{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18b787ef",
   "metadata": {},
   "source": [
    "# EDA for X-ray Hand Semantic Segmentation\n",
    "This notebook performs exploratory data analysis on the X-ray hand dataset for a semantic segmentation task involving 29 bones. The data includes images of left and right hands for each person, with corresponding annotations in JSON format.\n",
    "\n",
    "The notebook covers:\n",
    "- Basic dataset overview\n",
    "- Class distribution analysis\n",
    "- Image and mask visualization\n",
    "- Intensity distribution in X-ray images\n",
    "- Data augmentation examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8358410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from albumentations import HorizontalFlip, Rotate, RandomBrightnessContrast, Compose\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062f7e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define dataset paths\n",
    "data_dir = '/data/ephemeral/home/data/train/DCM'\n",
    "annotation_dir = '/data/ephemeral/home/data/train/outputs_json'\n",
    "image_paths = sorted(glob(os.path.join(data_dir, 'ID*/*.png')))\n",
    "annotation_paths = sorted(glob(os.path.join(annotation_dir, 'ID*/*.json')))\n",
    "\n",
    "print(f\"Total images: {len(image_paths)}\")\n",
    "print(f\"Total annotations: {len(annotation_paths)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2cf188",
   "metadata": {},
   "source": [
    "### 이미지와 Annotation 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35308f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_and_annotations(image_path, annotation_path):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        print(f\"Error: Could not load image at {image_path}\")\n",
    "        return\n",
    "    image = cv2.resize(image, (512, 512))\n",
    "    \n",
    "    # Initialize mask\n",
    "    mask = np.zeros_like(image)\n",
    "    \n",
    "    # Load annotation and create mask\n",
    "    try:\n",
    "        with open(annotation_path, 'r') as f:\n",
    "            annotation_data = json.load(f)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Could not decode JSON at {annotation_path}\")\n",
    "        return\n",
    "\n",
    "    # Draw each polygon for bones\n",
    "    try:\n",
    "        for bone in annotation_data['annotations']:\n",
    "            # Extract and reshape points for cv2.fillPoly\n",
    "            points = np.array(bone['points'], dtype=np.int32)\n",
    "            if points.size > 0:  # Ensure there are points to draw\n",
    "                points = points.reshape((-1, 1, 2))  # Reshape for cv2.fillPoly\n",
    "                cv2.fillPoly(mask, [points], 255)\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Missing expected key in JSON data - {e}\")\n",
    "        return\n",
    "\n",
    "    # Display image and mask\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(image, cmap='gray')\n",
    "    axes[0].set_title('X-ray Image')\n",
    "    axes[1].imshow(mask, cmap='gray')\n",
    "    axes[1].set_title('Bone Mask')\n",
    "    plt.show()\n",
    "\n",
    "# Display sample\n",
    "display_image_and_annotations(image_paths[0], annotation_paths[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc9a2f",
   "metadata": {},
   "source": [
    "### 각 클래스별 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550d047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate class distribution\n",
    "class_counts = {}\n",
    "for ann_path in tqdm(annotation_paths):\n",
    "    with open(ann_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for bone in data['annotations']:\n",
    "        label = bone['label']\n",
    "        if label not in class_counts:\n",
    "            class_counts[label] = 0\n",
    "        class_counts[label] += 1\n",
    "\n",
    "# Display class distribution\n",
    "class_df = pd.DataFrame(list(class_counts.items()), columns=['Bone', 'Count']).sort_values(by='Count', ascending=False)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=class_df, x='Bone', y='Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Class Distribution Across Bone Types\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a788c2",
   "metadata": {},
   "source": [
    "### 이미지의 intensity 를 통한 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7b7d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample pixel intensity distribution\n",
    "sample_images = [cv2.imread(img, cv2.IMREAD_GRAYSCALE) for img in image_paths[:10]]\n",
    "all_pixels = np.concatenate([img.flatten() for img in sample_images])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(all_pixels, bins=50, kde=True)\n",
    "plt.title(\"Pixel Intensity Distribution in X-ray Images\")\n",
    "plt.xlabel(\"Pixel Intensity\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a46ab",
   "metadata": {},
   "source": [
    "### 이미지에 intensity 범위별 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7960126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize_intensity(image, bins, colors):\n",
    "    \"\"\"\n",
    "    Colorize image based on intensity levels.\n",
    "    - image: Grayscale input image (2D array).\n",
    "    - bins: List of intensity boundaries to categorize.\n",
    "    - colors: List of colors to apply for each intensity bin.\n",
    "    \"\"\"\n",
    "    # Convert grayscale to BGR\n",
    "    color_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "        # Define mask for current intensity range\n",
    "        mask = cv2.inRange(image, bins[i], bins[i+1] - 1)\n",
    "        # Apply color to current intensity range\n",
    "        color_image[mask > 0] = colors[i]\n",
    "\n",
    "    return color_image\n",
    "\n",
    "# Load and resize sample image\n",
    "image_path = image_paths[0]\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, (512, 512))\n",
    "\n",
    "# Define intensity bins and corresponding colors (in BGR format)\n",
    "bins = [0, 32, 64, 96, 128, 160, 192, 224, 256]\n",
    "colors = [\n",
    "    (128, 0, 128),  # Purple for lowest intensity\n",
    "    (0, 0, 255),    # Red\n",
    "    (0, 128, 255),  # Orange\n",
    "    (0, 255, 255),  # Yellow\n",
    "    (0, 255, 0),    # Green\n",
    "    (255, 255, 0),  # Cyan\n",
    "    (255, 0, 0),    # Blue\n",
    "    (255, 0, 255),  # Magenta for highest intensity\n",
    "]\n",
    "\n",
    "# Colorize image\n",
    "colorized_image = colorize_intensity(image, bins, colors)\n",
    "\n",
    "# Display original and colorized images\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(image, cmap='gray')\n",
    "axes[0].set_title('Original Grayscale Image')\n",
    "axes[1].imshow(colorized_image)\n",
    "axes[1].set_title('Colorized Image by Intensity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7894ab",
   "metadata": {},
   "source": [
    "### 이미지에 intensity 범위별 시각화2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4f5d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize_intensity(image, bins, colors):\n",
    "    \"\"\"\n",
    "    Colorize image based on intensity levels.\n",
    "    - image: Grayscale input image (2D array).\n",
    "    - bins: List of intensity boundaries to categorize.\n",
    "    - colors: List of colors to apply for each intensity bin.\n",
    "    \"\"\"\n",
    "    # Convert grayscale to BGR\n",
    "    color_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "        # Define mask for current intensity range\n",
    "        mask = cv2.inRange(image, bins[i], bins[i+1])\n",
    "        # Apply color to current intensity range\n",
    "        color_image[mask > 0] = colors[i]\n",
    "\n",
    "    return color_image\n",
    "\n",
    "# Load and resize sample image\n",
    "image_path = image_paths[0]\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, (512, 512))\n",
    "\n",
    "# Define intensity bins and corresponding colors (in BGR format)\n",
    "bins = [0, 85, 170, 255]  # Example: low, medium, high intensity ranges\n",
    "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]  # Blue, Green, Red for each range\n",
    "\n",
    "# Colorize image\n",
    "colorized_image = colorize_intensity(image, bins, colors)\n",
    "\n",
    "# Display original and colorized images\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(image, cmap='gray')\n",
    "axes[0].set_title('Original Grayscale Image')\n",
    "axes[1].imshow(colorized_image)\n",
    "axes[1].set_title('Colorized Image by Intensity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc99f26",
   "metadata": {},
   "source": [
    "### 각 클래스별 뼈 면적 픽셀수와 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0786fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate pixel area and ratio for each class in an image\n",
    "def calculate_pixel_area_ratio(image_path, annotation_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    image_area = image.shape[0] * image.shape[1]\n",
    "    class_areas = {}\n",
    "\n",
    "    for bone in data['annotations']:\n",
    "        label = bone['label']\n",
    "        mask = np.zeros_like(image, dtype=np.uint8)\n",
    "        \n",
    "        # Using the 'points' key to get polygon points for each annotation\n",
    "        cv2.fillPoly(mask, [np.array(bone['points'], dtype=np.int32)], 1)\n",
    "        class_pixel_count = np.sum(mask)\n",
    "\n",
    "        if label not in class_areas:\n",
    "            class_areas[label] = {'pixel_area': 0, 'ratio': 0.0}\n",
    "        \n",
    "        class_areas[label]['pixel_area'] += class_pixel_count\n",
    "        class_areas[label]['ratio'] = class_areas[label]['pixel_area'] / image_area\n",
    "    \n",
    "    return class_areas\n",
    "\n",
    "# Apply to all images and gather results\n",
    "results = []\n",
    "for image_path, ann_path in zip(image_paths, annotation_paths):\n",
    "    class_areas = calculate_pixel_area_ratio(image_path, ann_path)\n",
    "    for class_label, metrics in class_areas.items():\n",
    "        results.append({\n",
    "            'Image': image_path,\n",
    "            'Class': class_label,\n",
    "            'Pixel Area': metrics['pixel_area'],\n",
    "            'Ratio': metrics['ratio']\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame and display\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.head())\n",
    "\n",
    "# Plot total pixel area and ratio for each class\n",
    "class_totals = results_df.groupby('Class').sum().reset_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=class_totals, x='Class', y='Pixel Area')\n",
    "plt.title(\"Total Pixel Area by Class\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=class_totals, x='Class', y='Ratio')\n",
    "plt.title(\"Average Ratio by Class\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272306da",
   "metadata": {},
   "source": [
    "### 겹치는 뼈의 면적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e82dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 겹치는 뼈 클래스의 면적을 계산하는 함수\n",
    "def calculate_overlap_area(image_path, annotation_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    class_masks = {}\n",
    "    overlap_results = {}\n",
    "\n",
    "    # 각 클래스에 대해 마스크 생성\n",
    "    for bone in data['annotations']:\n",
    "        label = bone['label']\n",
    "        mask = np.zeros_like(image, dtype=np.uint8)\n",
    "        \n",
    "        # 폴리곤 좌표를 사용하여 마스크 생성\n",
    "        cv2.fillPoly(mask, [np.array(bone['points'], dtype=np.int32)], 1)\n",
    "        class_masks[label] = mask\n",
    "\n",
    "    # 클래스 쌍의 조합 생성 (대칭 유지 위해 사전순으로 정렬)\n",
    "    for (class1, mask1), (class2, mask2) in combinations(class_masks.items(), 2):\n",
    "        sorted_class1, sorted_class2 = sorted([class1, class2])  # 클래스 이름을 사전순으로 정렬\n",
    "        overlap = np.logical_and(mask1, mask2).sum()\n",
    "        if overlap > 0:\n",
    "            if sorted_class1 not in overlap_results:\n",
    "                overlap_results[sorted_class1] = {}\n",
    "            overlap_results[sorted_class1][sorted_class2] = overlap\n",
    "\n",
    "    return overlap_results\n",
    "\n",
    "# 모든 이미지에 대해 결과 수집\n",
    "all_overlap_results = []\n",
    "for image_path, ann_path in zip(image_paths, annotation_paths):\n",
    "    overlap_results = calculate_overlap_area(image_path, ann_path)\n",
    "    for class1, overlaps in overlap_results.items():\n",
    "        for class2, overlap_area in overlaps.items():\n",
    "            all_overlap_results.append({\n",
    "                'Image': image_path,\n",
    "                'Class1': class1,\n",
    "                'Class2': class2,\n",
    "                'Overlap Area': overlap_area\n",
    "            })\n",
    "\n",
    "# 데이터프레임으로 변환하여 출력\n",
    "overlap_df = pd.DataFrame(all_overlap_results)\n",
    "\n",
    "# 클래스별 겹치는 면적을 보기 위해 피벗 테이블 생성\n",
    "overlap_pivot = overlap_df.pivot_table(index='Class1', columns='Class2', values='Overlap Area', fill_value=0)\n",
    "print(overlap_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3eb06c",
   "metadata": {},
   "source": [
    "### 겹치는 뼈 행렬을 히트맵으로 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ee379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 겹치는 뼈 행렬을 히트맵으로 시각화\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(overlap_pivot, annot=False, fmt=\".1f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Overlap Area'})\n",
    "plt.title(\"Bone Overlap Heatmap\")\n",
    "plt.xlabel(\"Bone Class 2\")\n",
    "plt.ylabel(\"Bone Class 1\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fbb07c",
   "metadata": {},
   "source": [
    "### 3개 이상 겹치는 클래스 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95212390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# 3개 이상의 클래스가 겹치는 경우를 분석하는 함수\n",
    "def analyze_multiple_class_overlap(image_path, annotation_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    class_masks = {}\n",
    "\n",
    "    # 각 클래스에 대해 마스크 생성\n",
    "    for bone in data['annotations']:\n",
    "        label = bone['label']\n",
    "        mask = np.zeros_like(image, dtype=np.uint8)\n",
    "        \n",
    "        # 폴리곤 좌표를 사용하여 마스크 생성\n",
    "        cv2.fillPoly(mask, [np.array(bone['points'], dtype=np.int32)], 1)\n",
    "        class_masks[label] = mask\n",
    "\n",
    "    # 모든 클래스 마스크를 쌓아서 겹치는 픽셀 계산\n",
    "    stacked_mask = np.zeros_like(image, dtype=np.uint8)\n",
    "    for mask in class_masks.values():\n",
    "        stacked_mask += mask\n",
    "\n",
    "    # 3개 이상의 클래스가 겹치는 픽셀 위치 찾기\n",
    "    overlap_class_combinations = defaultdict(int)\n",
    "    overlap_pixels = np.where(stacked_mask >= 3)  # 3개 이상의 클래스가 겹치는 위치\n",
    "\n",
    "    # 3개 이상의 클래스가 겹치는 픽셀에 포함된 클래스 조합 계산\n",
    "    for y, x in zip(*overlap_pixels):\n",
    "        overlapping_classes = [label for label, mask in class_masks.items() if mask[y, x] == 1]\n",
    "        overlapping_classes.sort()  # 조합을 일정하게 유지하기 위해 정렬\n",
    "        if len(overlapping_classes) >= 3:\n",
    "            overlap_class_combinations[tuple(overlapping_classes)] += 1\n",
    "\n",
    "    return overlap_class_combinations\n",
    "\n",
    "# 모든 이미지에 대해 결과 수집\n",
    "all_overlap_results = defaultdict(int)\n",
    "for image_path, ann_path in zip(image_paths, annotation_paths):\n",
    "    overlap_results = analyze_multiple_class_overlap(image_path, ann_path)\n",
    "    for classes, count in overlap_results.items():\n",
    "        all_overlap_results[classes] += count\n",
    "\n",
    "# 데이터프레임으로 변환하여 출력\n",
    "overlap_df = pd.DataFrame(list(all_overlap_results.items()), columns=[\"Class Combination\", \"Count\"])\n",
    "overlap_df = overlap_df.sort_values(by=\"Count\", ascending=False)\n",
    "print(overlap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80568f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보기 안좋음, 사용 안함\n",
    "\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.lines import Line2D\n",
    "# import numpy as np\n",
    "\n",
    "# # 클래스마다 고유한 색상을 정의\n",
    "# class_colors = {}\n",
    "# unique_classes = list(set(overlap_df['Class1']).union(set(overlap_df['Class2'])))\n",
    "# color_map = plt.cm.get_cmap('tab20', len(unique_classes))  # 다양한 색상 선택을 위해 tab20 컬러맵 사용\n",
    "# for idx, cls in enumerate(unique_classes):\n",
    "#     class_colors[cls] = color_map(idx)\n",
    "\n",
    "# # 그래프 생성 및 엣지 추가\n",
    "# G = nx.Graph()\n",
    "# for _, row in overlap_df.iterrows():\n",
    "#     if row['Overlap Area'] > 0:\n",
    "#         G.add_edge(row['Class1'], row['Class2'], weight=row['Overlap Area'])\n",
    "\n",
    "# # 노드 위치 설정\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# pos = nx.spring_layout(G, k=0.5, seed=42)\n",
    "\n",
    "# # 엣지 두께 및 색상 설정 (첫 번째 노드의 색상 사용)\n",
    "# weights = [G[u][v]['weight'] / 100 for u, v in G.edges()]\n",
    "# edge_colors = [class_colors[u] for u, v in G.edges()]\n",
    "# nx.draw_networkx_edges(\n",
    "#     G, pos, edge_color=edge_colors, width=weights, alpha=0.5\n",
    "# )\n",
    "\n",
    "# # 노드 색상 및 투명도 설정\n",
    "# node_colors = [class_colors[node] for node in G.nodes()]\n",
    "# nx.draw_networkx_nodes(G, pos, node_size=3000, node_color=node_colors, alpha=0.7)\n",
    "# nx.draw_networkx_labels(G, pos, font_size=10)\n",
    "\n",
    "# # 범례 추가 (클래스-색 매핑)\n",
    "# legend_elements = [Line2D([0], [0], marker='o', color='w', label=cls,\n",
    "#                           markerfacecolor=class_colors[cls], markersize=10, alpha=0.7)\n",
    "#                    for cls in unique_classes]\n",
    "# plt.legend(handles=legend_elements, loc=\"upper left\", title=\"Bone Class Colors\")\n",
    "\n",
    "# plt.title(\"Bone Overlap Graph\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4ab146",
   "metadata": {},
   "source": [
    "### 왼손 Flip 한 이미지와 오른손 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc08a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 두 이미지 간 MSE 및 SSIM 계산 함수\n",
    "def calculate_similarity(image1, image2):\n",
    "    # Mean Squared Error (MSE)\n",
    "    mse_value = mean_squared_error(image1.ravel(), image2.ravel())\n",
    "    \n",
    "    # Structural Similarity Index (SSIM)\n",
    "    ssim_value, diff = ssim(image1, image2, full=True)\n",
    "    return mse_value, ssim_value, diff\n",
    "\n",
    "# 시각적 비교 및 분석 함수\n",
    "def visualize_comparison(left_image, right_image, flipped_left_image, diff):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # 왼손 이미지\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.imshow(left_image, cmap='gray')\n",
    "    plt.title(\"Original Left Hand\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # 오른손 이미지\n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.imshow(right_image, cmap='gray')\n",
    "    plt.title(\"Original Right Hand\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # 플립된 왼손 이미지\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.imshow(flipped_left_image, cmap='gray')\n",
    "    plt.title(\"Flipped Left Hand\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # 차이 이미지 (절대 값 차이)\n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.imshow(np.abs(right_image - flipped_left_image), cmap='hot')\n",
    "    plt.title(\"Absolute Difference\")\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    # SSIM 차이 이미지\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.imshow(diff, cmap='hot')\n",
    "    plt.title(\"SSIM Difference Map\")\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 왼손-오른손 이미지 유사성 비교 함수\n",
    "def compare_left_right_hands(left_hand_path, right_hand_path):\n",
    "    # 이미지 로드 및 전처리\n",
    "    left_image = cv2.imread(left_hand_path, cv2.IMREAD_GRAYSCALE)\n",
    "    right_image = cv2.imread(right_hand_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # 이미지 크기를 맞추기\n",
    "    if left_image.shape != right_image.shape:\n",
    "        right_image = cv2.resize(right_image, (left_image.shape[1], left_image.shape[0]))\n",
    "\n",
    "    # 왼손 이미지를 수평 플립\n",
    "    flipped_left_image = cv2.flip(left_image, 1)\n",
    "\n",
    "    # 유사도 계산\n",
    "    mse_value, ssim_value, diff = calculate_similarity(flipped_left_image, right_image)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f\"Mean Squared Error (MSE): {mse_value}\")\n",
    "    print(f\"Structural Similarity Index (SSIM): {ssim_value}\")\n",
    "    \n",
    "    # 시각화\n",
    "    visualize_comparison(left_image, right_image, flipped_left_image, diff)\n",
    "\n",
    "# 예제 실행\n",
    "left_hand_image_path = \"/data/ephemeral/home/data/train/DCM/ID001/image1661130828152_R.png\"  # 왼손 이미지 경로\n",
    "right_hand_image_path = \"/data/ephemeral/home/data/train/DCM/ID001/image1661130891365_L.png\"  # 오른손 이미지 경로\n",
    "\n",
    "compare_left_right_hands(left_hand_image_path, right_hand_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ea8f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 로드\n",
    "# submission = pd.read_csv(\"/data/ephemeral/home/jseo/val.csv\")\n",
    "# ground_truth = pd.read_csv(\"path_to_ground_truth.csv\")\n",
    "\n",
    "# # 예제 데이터가 주어졌다고 가정: id, class, x, y, width, height\n",
    "# # 예: id, class, x, y, width, height (bounding box 형태)\n",
    "\n",
    "# # 데이터프레임 정렬\n",
    "# submission = submission.sort_values(by=\"id\").reset_index(drop=True)\n",
    "# ground_truth = ground_truth.sort_values(by=\"id\").reset_index(drop=True)\n",
    "\n",
    "# # 시각화 함수\n",
    "# def visualize_differences(submission, ground_truth):\n",
    "#     ids = submission['id'].unique()\n",
    "#     for img_id in ids:\n",
    "#         # 이미지와 예측, GT 데이터를 필터링\n",
    "#         sub_data = submission[submission['id'] == img_id]\n",
    "#         gt_data = ground_truth[ground_truth['id'] == img_id]\n",
    "\n",
    "#         # 이미지 로드 (실제 경로 필요)\n",
    "#         img_path = f\"path_to_images/{img_id}.jpg\"  # 이미지 경로 설정\n",
    "#         image = cv2.imread(img_path)\n",
    "#         if image is None:\n",
    "#             print(f\"Image {img_id} not found.\")\n",
    "#             continue\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#         # 이미지 시각화\n",
    "#         fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "#         ax.imshow(image)\n",
    "        \n",
    "#         # GT 박스 (녹색)\n",
    "#         for _, row in gt_data.iterrows():\n",
    "#             x, y, w, h = row['x'], row['y'], row['width'], row['height']\n",
    "#             rect = plt.Rectangle((x, y), w, h, linewidth=2, edgecolor='green', facecolor='none', label=\"Ground Truth\")\n",
    "#             ax.add_patch(rect)\n",
    "        \n",
    "#         # Submission 박스 (빨간색)\n",
    "#         for _, row in sub_data.iterrows():\n",
    "#             x, y, w, h = row['x'], row['y'], row['width'], row['height']\n",
    "#             rect = plt.Rectangle((x, y), w, h, linewidth=2, edgecolor='red', facecolor='none', label=\"Prediction\")\n",
    "#             ax.add_patch(rect)\n",
    "        \n",
    "#         # 중복되는 범례 제거\n",
    "#         handles, labels = ax.get_legend_handles_labels()\n",
    "#         by_label = dict(zip(labels, handles))\n",
    "#         ax.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "#         plt.title(f\"Comparison for Image {img_id}\")\n",
    "#         plt.axis('off')\n",
    "#         plt.show()\n",
    "\n",
    "# # 실행\n",
    "# visualize_differences(submission, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b7fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define data augmentation pipeline\n",
    "augmentation = Compose([\n",
    "    HorizontalFlip(p=0.5),\n",
    "    Rotate(limit=30, p=0.5),\n",
    "    RandomBrightnessContrast(p=0.5),\n",
    "])\n",
    "\n",
    "def augment_and_display(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (512, 512))\n",
    "    augmented_image = augmentation(image=image)['image']\n",
    "\n",
    "    # Display original and augmented images\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(image, cmap='gray')\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "    axes[1].imshow(augmented_image, cmap='gray')\n",
    "    axes[1].set_title(\"Augmented Image\")\n",
    "    plt.show()\n",
    "\n",
    "# Show augmentation example\n",
    "augment_and_display(image_paths[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
